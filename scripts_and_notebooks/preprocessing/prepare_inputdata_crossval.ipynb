{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a498da6-a904-490f-9225-c5e69c937927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Sep 08 11:15 2022\n",
    "\n",
    "This script is to prepare the normalising coefficients and input data for the cross-validation\n",
    "\n",
    "Author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62683553-5f6d-4aff-bc72-48afd2a44509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from nn_functions.constants import *\n",
    "import nn_functions.prep_input_data as indat\n",
    "\n",
    "import distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53473f-448b-4330-83cc-38f8f2e56973",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(n_workers=12, dashboard_address=':8795', local_directory='/tmp', memory_limit='6GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d8e89-2eda-46fc-8660-bf0ed28cf632",
   "metadata": {},
   "source": [
    "PREPARE THE CONTEXT OF THE INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457f121-607f-4f0e-8941-b59bc0cd8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath_data = '/bettik/burgardc/DATA/NN_PARAM/interim/INPUT_DATA/' \n",
    "\n",
    "tblock_dim = range(1,14)\n",
    "isf_dim = [10,11,12,13,18,22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b4415-3359-44ce-841e-a3d1f89defd3",
   "metadata": {},
   "source": [
    "CV over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141148ac-86c2-485f-8858-a760d5ea9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "tblock_dim = range(1,14)\n",
    "isf_dim = [10,11,12,13,18,22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "TS_opt = 'extrap'\n",
    "\n",
    "if TS_opt == 'extrap':\n",
    "    outputpath_CVinput = inputpath_data+'EXTRAPOLATED_ISFDRAFT_CHUNKS_CV/'\n",
    "elif TS_opt == 'whole':\n",
    "    outputpath_CVinput = inputpath_data+'WHOLE_PROF_CHUNKS_CV/'\n",
    "elif TS_opt == 'thermocline':\n",
    "    outputpath_CVinput = inputpath_data+'THERMOCLINE_CHUNKS_CV/'\n",
    "\n",
    "for tblock_out in tblock_dim:\n",
    "    print(tblock_out)\n",
    "\n",
    "    isf_out = 0\n",
    "    metrics_ds, var_train_norm, var_val_norm = indat.prepare_input_data_CV(tblock_dim, isf_dim, tblock_out, isf_out, TS_opt, inputpath_data)\n",
    "    #metrics_ds = indat.prepare_input_data_CV_onlymetrics(tblock_dim, isf_dim, tblock_out, isf_out, TS_opt, inputpath_data)\n",
    "    metrics_ds.to_netcdf(outputpath_CVinput + 'metrics_norm_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "    var_train_norm.to_netcdf(outputpath_CVinput + 'train_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "    var_val_norm.to_netcdf(outputpath_CVinput + 'val_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5b63c-022f-442d-81cd-0eda1f0ddada",
   "metadata": {},
   "source": [
    "CV over shelves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab196a5-3965-4225-b9f6-002f19d08c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tblock_dim = range(1,14)\n",
    "isf_dim = [10,11,12,13,18,22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "#isf_dim = [22,23,24,25,30,31,33,38,39,40,42,43,44,45,47,48,51,52,53,54,55,58,61,65,66,69,70,71,73,75]\n",
    "TS_opt = 'extrap'\n",
    "\n",
    "if TS_opt == 'extrap':\n",
    "    outputpath_CVinput = inputpath_data+'EXTRAPOLATED_ISFDRAFT_CHUNKS_CV/'\n",
    "elif TS_opt == 'whole':\n",
    "    outputpath_CVinput = inputpath_data+'WHOLE_PROF_CHUNKS_CV/'\n",
    "elif TS_opt == 'thermocline':\n",
    "    outputpath_CVinput = inputpath_data+'THERMOCLINE_CHUNKS_CV/'\n",
    "    \n",
    "for isf_out in isf_dim:\n",
    "    print(isf_out)\n",
    "    \n",
    "    tblock_out = 0\n",
    "    metrics_ds, var_train_norm, var_val_norm = indat.prepare_input_data_CV(tblock_dim, isf_dim, tblock_out, isf_out, TS_opt, inputpath_data)\n",
    "    #metrics_ds = indat.prepare_input_data_CV_onlymetrics(tblock_dim, isf_dim, tblock_out, isf_out, TS_opt, inputpath_data)\n",
    "    metrics_ds.to_netcdf(outputpath_CVinput + 'metrics_norm_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "    var_train_norm.to_netcdf(outputpath_CVinput + 'train_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "    var_val_norm.to_netcdf(outputpath_CVinput + 'val_data_CV_noisf'+str(isf_out).zfill(3)+'_notblock'+str(tblock_out).zfill(3)+'.nc')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnet",
   "language": "python",
   "name": "neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
