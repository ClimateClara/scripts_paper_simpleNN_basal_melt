{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Feb 15 11:43 2021\n",
    "\n",
    "use script to identify (potentially changing in time) ice shelves in NEMO data from Smith\n",
    "\n",
    "@author: Clara Burgard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import multimelt.plume_functions as pf\n",
    "import multimelt.box_functions as bf\n",
    "import multimelt.useful_functions as uf\n",
    "import multimelt.create_isf_mask_functions as isfmf\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lim = [-3000000,3000000]\n",
    "\n",
    "#chunk_size = 700\n",
    "chunk_size = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b12b8-3089-42cf-9d35-0487c31e43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nemo_run = 'bi646' # 'bf663','bi646'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### READ IN DATA\n",
    "######\n",
    "\n",
    "\n",
    "#if run on luke\n",
    "inputpath_data='/bettik/burgardc/DATA/NN_PARAM/interim/SMITH_'+nemo_run+'/'\n",
    "inputpath_metadata='/bettik/burgardc/SCRIPTS/basal_melt_param/data/raw/MASK_METADATA/'\n",
    "outputpath_mask='/bettik/burgardc/DATA/NN_PARAM/interim/ANTARCTICA_IS_MASKS/SMITH_'+nemo_run+'/'\n",
    "outputpath_boxes = '/bettik/burgardc/DATA/NN_PARAM/interim/BOXES/SMITH_'+nemo_run+'/'\n",
    "outputpath_plumes = '/bettik/burgardc/DATA/NN_PARAM/interim/PLUMES/SMITH_'+nemo_run+'/'\n",
    "\n",
    "file_mask_orig = xr.open_dataset(inputpath_data+'other_mask_vars_Ant_stereo.nc')\n",
    "file_mask_orig_cut = uf.cut_domain_stereo(file_mask_orig, map_lim, map_lim)\n",
    "\n",
    "file_mask = xr.open_dataset(inputpath_data+'custom_lsmask_Ant_stereo_clean.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_mask_cut = uf.cut_domain_stereo(file_mask, map_lim, map_lim)\n",
    "\n",
    "file_other = xr.open_dataset(inputpath_data+'corrected_draft_bathy_isf.nc')#, chunks={'x': chunk_size, 'y': chunk_size})\n",
    "file_other_cut = uf.cut_domain_stereo(file_other, map_lim, map_lim)\n",
    "\n",
    "file_conc = xr.open_dataset(inputpath_data+'isfdraft_conc_Ant_stereo.nc')\n",
    "file_conc_cut = uf.cut_domain_stereo(file_conc, map_lim, map_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-davis",
   "metadata": {},
   "source": [
    "Create the masks for ice shelves/ground/pinning points/grounding line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2bc76-f17d-464e-9595-00f4892af9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timet = 10\n",
    "#print('Timestep :'+str(timet.values).zfill(2))\n",
    "\n",
    "file_TS_orig = xr.open_dataset(inputpath_data + '3D_variables_of_interest_allyy_Ant_stereo_'+str(1970 + timet)+'.nc').isel(time=0).drop('time')\n",
    "file_TS_cut = uf.cut_domain_stereo(file_TS_orig, map_lim, map_lim)\n",
    "\n",
    "file_bed_orig = file_mask_orig_cut['bathy_metry'].sel(time=timet).drop('time')\n",
    "file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "file_msk = file_mask_cut['ls_mask012'].sel(time=timet).where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "file_isf_conc = file_conc_cut['isfdraft_conc'].sel(time=timet).drop('time')\n",
    "\n",
    "xx = file_mask_cut['x']\n",
    "yy = file_mask_cut['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a578e-6c65-461f-8d75-8bf7d44e15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds_tt = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                          '/bettik/burgardc/DATA/NN_PARAM/interim/basins_mask_extrap_50km.nc', outputpath_mask, \n",
    "                                          inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                          inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=True,\n",
    "                                          write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                          ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                          write_metadata='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bd6b9-6957-4610-b86f-5d9c00cb9b54",
   "metadata": {},
   "source": [
    "WITH VARIABLE GEOMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064965d8-eea5-49ff-b0f4-0d98723bf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "\n",
    "    file_TS_orig = xr.open_dataset(inputpath_data + '3D_variables_of_interest_allyy_Ant_stereo_'+str(timet.values.astype(int))+'.nc').isel(time=0).drop('time')\n",
    "    file_TS_cut = uf.cut_domain_stereo(file_TS_orig, map_lim, map_lim)\n",
    "\n",
    "    file_bed_orig = file_mask_orig_cut['bathy_metry'].sel(time=timet).drop('time')\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "    file_msk = file_mask_cut['ls_mask012'].sel(time=timet)#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "    file_isf_conc = file_conc_cut['isfdraft_conc'].sel(time=timet).drop('time')\n",
    "    \n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "    \n",
    "    whole_ds_tt = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                              inputpath_metadata+'lonlat_masks.txt', outputpath_mask, \n",
    "                                              inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                              inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=False, variable_geometry=True,\n",
    "                                              write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                              ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                              write_metadata='yes')\n",
    "\n",
    "    print('------- WRITE TO NETCDF -----------')\n",
    "    whole_ds_tt.to_netcdf(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a25223-38ba-4cec-a5b0-2cfb8b3d0c0d",
   "metadata": {},
   "source": [
    "WITH MOUGINOT BASINS (BUT MISSING SOME PARTS IN VARIABLE GEOMETRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6243a-3967-423e-9804-b1102f96f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "\n",
    "    file_TS_orig = xr.open_dataset(inputpath_data + '3D_variables_of_interest_allyy_Ant_stereo_'+str(timet.values.astype(int))+'.nc').isel(time=0).drop('time')\n",
    "    file_TS_cut = uf.cut_domain_stereo(file_TS_orig, map_lim, map_lim)\n",
    "\n",
    "    file_bed_orig = file_mask_orig_cut['bathy_metry'].sel(time=timet).drop('time')\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "    file_msk = file_mask_cut['ls_mask012'].sel(time=timet)#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "    file_isf_conc = file_conc_cut['isfdraft_conc'].sel(time=timet).drop('time')\n",
    "    \n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "    \n",
    "    whole_ds_tt = isfmf.create_mask_and_metadata_isf(file_msk, -1*file_bed_orig, file_msk, -1*file_draft, file_isf_conc, False, \n",
    "                                              '/bettik/burgardc/DATA/NN_PARAM/interim/basins_mask_extrap_50km.nc', outputpath_mask, \n",
    "                                              inputpath_metadata + 'iceshelves_metadata_Nico.txt', \n",
    "                                              inputpath_metadata+'GL_flux_rignot13.csv', mouginot_basins=True, variable_geometry=False,\n",
    "                                              write_ismask = 'yes', write_groundmask = 'yes', write_outfile='yes',\n",
    "                                              ground_point ='no',dist=40, add_fac=120, connectivity=4, threshold=4,\n",
    "                                              write_metadata='yes')\n",
    "\n",
    "    print('------- WRITE TO NETCDF -----------')\n",
    "    whole_ds_tt.to_netcdf(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-annual",
   "metadata": {},
   "source": [
    "Prepare the box characteristics (writes the output directly to files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))): \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "    file_bed_orig = file_mask_orig_cut['bathy_metry'].sel(time=timet).drop('time')\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "    file_msk = file_mask_cut['ls_mask012'].sel(time=timet)#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "    file_isf_conc = file_conc_cut['isfdraft_conc'].sel(time=timet).drop('time')\n",
    "\n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "\n",
    "    whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "\n",
    "    nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "\n",
    "    isf_var_of_int = whole_ds_tt[['ISF_mask', 'GL_mask', 'dGL', 'dIF', 'latitude', 'longitude', 'isf_name']]\n",
    "    out_2D, out_1D = bf.box_charac_file(file_isf['Nisf'],isf_var_of_int, -1*file_draft, file_isf_conc, outputpath_boxes, max_nb_box=10)\n",
    "    out_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    out_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138d00e-a3c7-45d7-b3e0-f57c45d7566e",
   "metadata": {},
   "source": [
    "FOR WILKINS AND BACH (BECAUSE HAD A PROBLEM IN FIRST PREPROCESSING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9d1f6-fdc3-4799-91bb-7d67af511a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "    file_bed_orig = file_mask_orig_cut['bathy_metry'].sel(time=timet).drop('time')\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "    file_msk = file_mask_cut['ls_mask012'].sel(time=timet)#.where((file_TS_cut['so'].max('deptht') > 0), 2).drop('time') #0 = ocean, 1 = ice shelves, 2 = grounded ice\n",
    "    file_isf_conc = file_conc_cut['isfdraft_conc'].sel(time=timet).drop('time')\n",
    "\n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "\n",
    "    whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    \n",
    "    nisf_list = []\n",
    "    nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "    if 75 in large_isf:\n",
    "        nisf_list.append(75)\n",
    "    if 54 in file_isf.Nisf:\n",
    "        nisf_list.append(54)\n",
    "\n",
    "    isf_var_of_int = whole_ds_tt[['ISF_mask', 'GL_mask', 'dGL', 'dIF', 'latitude', 'longitude', 'isf_name']]\n",
    "    out_2D, out_1D = bf.box_charac_file(file_isf['Nisf'].sel(Nisf=nisf_list),isf_var_of_int, -1*file_draft, file_isf_conc, outputpath_boxes, max_nb_box=10)\n",
    "    out_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')\n",
    "    out_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b275637-a9a1-4f10-abee-f557c6a26d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timet in tqdm(file_mask_orig_cut.time.sel(time=range(1970,2051))): \n",
    "    #print(timet.values)\n",
    "    file_isf = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    out_2D_AI = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')\n",
    "    out_1D_AI = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')\n",
    "    out_2D_orig = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    out_1D_orig = xr.open_dataset(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "\n",
    "    merged_2D = out_2D_orig.where(file_isf['ISF_mask'] != 75, out_2D_AI).load()\n",
    "    merged_1D = xr.concat([out_1D_orig.drop_sel(Nisf=75),out_1D_AI], dim='Nisf').load()\n",
    "\n",
    "    merged_2D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_2D_oneFRIS_'+str(timet.values.astype(int))+'_merged75.nc', 'w')\n",
    "    merged_1D.to_netcdf(outputpath_boxes + 'nemo_5km_boxes_1D_oneFRIS_'+str(timet.values.astype(int))+'_merged75.nc', 'w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-ukraine",
   "metadata": {},
   "source": [
    "Prepare the plume characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_param_options = ['simple','lazero', 'appenB']\n",
    "\n",
    "\n",
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))): \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "\n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "\n",
    "    whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "\n",
    "    nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "\n",
    "    plume_var_of_int = file_isf[['ISF_mask', 'GL_mask', 'IF_mask', 'dIF', 'dGL_dIF', 'latitude', 'longitude', 'front_ice_depth_avg']]\n",
    "\n",
    "    # Compute the ice draft\n",
    "    ice_draft_pos = file_draft\n",
    "    ice_draft_neg = -1*ice_draft_pos\n",
    "\n",
    "\n",
    "    plume_charac = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int)\n",
    "    print('------ WRITE TO NETCDF -------')\n",
    "    plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_'+str(timet.values.astype(int))+'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9bc1bf-735d-4e88-8605-882f48154999",
   "metadata": {},
   "source": [
    "ONLY WILKINS AND BACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae2831-5676-4338-857e-e4012be44019",
   "metadata": {},
   "outputs": [],
   "source": [
    "plume_param_options = ['simple','lazero', 'appenB']\n",
    "\n",
    "\n",
    "for tt,timet in enumerate(file_mask_orig_cut.time.sel(time=range(1970,2051))): \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Timestep :'+str(timet.values).zfill(2))\n",
    "    file_draft = file_other_cut['corrected_isfdraft'].sel(time=timet).drop('time')\n",
    "\n",
    "    xx = file_mask_cut['x']\n",
    "    yy = file_mask_cut['y']\n",
    "\n",
    "    whole_ds_tt = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    \n",
    "    nisf_list = []\n",
    "    nonnan_Nisf = whole_ds_tt['Nisf'].where(np.isfinite(whole_ds_tt['front_bot_depth_max']), drop=True).astype(int)\n",
    "    file_isf_nonnan = whole_ds_tt.sel(Nisf=nonnan_Nisf)\n",
    "    large_isf = file_isf_nonnan['Nisf'].where(file_isf_nonnan['isf_area_here'] >= 2500, drop=True)\n",
    "    file_isf = file_isf_nonnan.sel(Nisf=large_isf)\n",
    "    if 'labels' in file_isf.coords.keys():\n",
    "        file_isf = file_isf.drop('labels')\n",
    "    if 75 in large_isf:\n",
    "        nisf_list.append(75)\n",
    "    if 54 in file_isf.Nisf:\n",
    "        nisf_list.append(54)\n",
    "    file_isf = file_isf.sel(Nisf=nisf_list)\n",
    "\n",
    "    plume_var_of_int = file_isf[['ISF_mask', 'GL_mask', 'IF_mask', 'dIF', 'dGL_dIF', 'latitude', 'longitude', 'front_ice_depth_avg']]\n",
    "\n",
    "    # Compute the ice draft\n",
    "    ice_draft_pos = file_draft\n",
    "    ice_draft_neg = -1*ice_draft_pos\n",
    "\n",
    "\n",
    "    plume_charac = pf.prepare_plume_charac(plume_param_options, ice_draft_pos, plume_var_of_int)\n",
    "    print('------ WRITE TO NETCDF -------')\n",
    "    #plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics.nc')\n",
    "    plume_charac.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d781bb-0a22-457d-bbf8-f7700cfdff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timet in file_mask_orig_cut.time.sel(time=range(1970,2051)): # continue at 1983\n",
    "    print(timet.values)\n",
    "    file_isf = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "    plume_AI = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_'+str(timet.values.astype(int))+'_only_AlexIsland.nc')\n",
    "    plume_orig = xr.open_dataset(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_'+str(timet.values.astype(int))+'.nc')\n",
    "\n",
    "    merged_plume = plume_orig.where(file_isf['ISF_mask'] != 75, plume_AI)\n",
    "\n",
    "    merged_plume.to_netcdf(outputpath_plumes+'nemo_5km_plume_characteristics_oneFRIS_'+str(timet.values.astype(int))+'_merged75.nc', 'w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072309c7-4cec-4c5f-9904-12c4eb355b17",
   "metadata": {},
   "source": [
    "Prepare correct bathymetry (accounting for ice shelf concentration but also if we are at ice front or grounding line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efc61c-7f27-4177-9793-54288e2dbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = xr.open_dataset(outputpath_mask + 'nemo_5km_isf_masks_and_info_and_distance_new_oneFRIS.nc')\n",
    "\n",
    "file_bed_orig = file_mask_orig_cut['bathy_metry']\n",
    "file_bed_corr = file_other_cut['corrected_isf_bathy']\n",
    "file_draft = file_other_cut['corrected_isfdraft'] \n",
    "\n",
    "file_bed_goodGL = file_bed_orig.where(file_draft < file_bed_orig,file_bed_corr)\n",
    "file_bed_goodGL_with_ocean =  file_bed_goodGL.where(whole_ds['ISF_mask'] > 1, file_bed_orig)\n",
    "file_bed_goodGL_with_ocean.to_dataset(name='bathymetry').to_netcdf(outputpath_mask + 'processed_bathymetry.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
